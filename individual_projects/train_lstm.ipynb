{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f60bfe3a-a284-4288-8772-9fa0ddd4c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Any, Tuple\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tensorflow import keras\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc7c83b7-1dce-4959-807c-e9ab23cba113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14555 14555\n",
      "5 I like R & B.\n"
     ]
    }
   ],
   "source": [
    "# file_eng = 'europarl-v7.fr-en.en'\n",
    "# file_fr = 'europarl-v7.fr-en.fr'\n",
    "\n",
    "# def load_data(path):\n",
    "    \n",
    "#     with  open(path, 'r', encoding=\"utf8\") as f:\n",
    "#         lines = f.read().splitlines() \n",
    "#     return lines[1100:1200]\n",
    "\n",
    "# clean_eng = load_data(file_eng)\n",
    "# clean_french = load_data(file_fr)\n",
    "\n",
    "path = 'eng_-french.csv'\n",
    "\n",
    "df = pd.read_csv('eng_-french.csv')\n",
    "df = df.rename(columns={\"English words/sentences\":\"Eng\", \"French words/sentences\":\"French\" })\n",
    " \n",
    "english = df['Eng']\n",
    "french = df['French']\n",
    "clean_eng = english[0:14555]\n",
    "clean_french = french[0:14555]\n",
    "\n",
    "targ = list(clean_french)\n",
    "inp = list(clean_eng)\n",
    "print(len(clean_eng),len(clean_french))\n",
    "max_w = 0\n",
    "m=None\n",
    "for i in clean_eng:\n",
    "    if len(i.split(' '))>max_w:\n",
    "        max_w = len(i.split(' '))\n",
    "        m = i\n",
    "print(max_w,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25e0940c-7188-456a-b20c-3d0aca2571e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4152 7912\n",
      "4152 7912\n"
     ]
    }
   ],
   "source": [
    "dict_inp=set(' '.join(inp).split(' '))\n",
    "dict_targ=set(' '.join(targ).split(' '))\n",
    "dict_inp = list(dict_inp)\n",
    "dict_targ = list(dict_targ)\n",
    "dict_inp.sort()\n",
    "dict_targ.sort()\n",
    "max_len_inp = len(dict_inp)\n",
    "max_len_targ = len(dict_targ)\n",
    "print(len(dict_inp),len(dict_targ))\n",
    "print(max_len_inp,max_len_targ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7749713-054f-4930-8577-1fa30ebedbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_id_inp = dict([(i,token) for i,token in enumerate(dict_inp)])\n",
    "# token_id_targ = dict([(i,token) for i,token in enumerate(dict_targ)])\n",
    "# max_len_inp = max([len(line) for line in inp])\n",
    "# max_len_targ = max([len(line) for line in targ])\n",
    "# print(max_len_inp)\n",
    "# print(max_len_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "58c3237b-eee8-4097-8102-960714744a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_inp = keras.preprocessing.text.Tokenizer()\n",
    "# tokenizer_targ = keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "# tokenizer_inp.fit_on_texts(inp)\n",
    "# tokenizer_targ.fit_on_texts(targ)\n",
    "\n",
    "# tokenized_inp = tokenizer_inp.texts_to_sequences(inp) \n",
    "# tokenized_targ = tokenizer_targ.texts_to_sequences(targ) \n",
    "# padded_inp = keras.preprocessing.sequence.pad_sequences(tokenized_inp,padding='post')\n",
    "# padded_targ = keras.preprocessing.sequence.pad_sequences(tokenized_targ,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d22dbe3f-1103-4f35-ba32-661484566bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_inp = preprocessing.TextVectorization(max_tokens=max_len_inp) \n",
    "preprocess_inp.adapt(inp)\n",
    "preprocess_targ = preprocessing.TextVectorization(max_tokens=max_len_targ) \n",
    "preprocess_targ.adapt(targ)\n",
    "vocab_inp = np.array(preprocess_inp.get_vocabulary())\n",
    "vocab_targ = np.array(preprocess_targ.get_vocabulary())\n",
    "x = preprocess_inp(inp).numpy()\n",
    "y = preprocess_targ(targ).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1fd3315e-8c62-4a84-8f38-6540b3a417e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14555, 5), (14555, 11))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_inp[preprocess_inp(inp[0]).numpy()]\n",
    "# preprocess_inp(inp[0])\n",
    "# len(vocab_inp)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b6f26d2-a1b8-4866-b7b4-eb64d83c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_inp = keras.layers.Embedding(input_dim=len(vocab_inp),output_dim=128,mask_zero=True)\n",
    "embedding_targ = keras.layers.Embedding(input_dim=len(vocab_targ),output_dim=128,mask_zero=True)\n",
    "\n",
    "xx = embedding_inp(x)\n",
    "yy = embedding_targ(y)\n",
    "xx.shape,yy.shape\n",
    "time_inp = xx.shape[1]\n",
    "time_targ = yy.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d48efa9-298d-4473-8ccb-5f7686340d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 5, 128)            359296    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 11, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 11, 6309)          813861    \n",
      "=================================================================\n",
      "Total params: 1,436,325\n",
      "Trainable params: 1,436,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(len(vocab_inp),batch_size,input_length=time_inp,mask_zero=True))\n",
    "model.add(keras.layers.LSTM(batch_size)) \n",
    "model.add(keras.layers.RepeatVector(time_targ))\n",
    "model.add(keras.layers.LSTM(batch_size,return_sequences=True))\n",
    "model.add(keras.layers.Dropout(.5))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(len(vocab_targ),activation='softmax')))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a600db15-34f4-4f7a-96e2-4408dff1083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "410/410 - 19s - loss: 2.1053 - accuracy: 0.7155 - val_loss: 2.3853 - val_accuracy: 0.6682\n",
      "Epoch 2/10\n",
      "410/410 - 18s - loss: 1.9848 - accuracy: 0.7212 - val_loss: 2.3349 - val_accuracy: 0.6724\n",
      "Epoch 3/10\n",
      "410/410 - 19s - loss: 1.9127 - accuracy: 0.7261 - val_loss: 2.2960 - val_accuracy: 0.6882\n",
      "Epoch 4/10\n",
      "410/410 - 19s - loss: 1.8410 - accuracy: 0.7335 - val_loss: 2.2429 - val_accuracy: 0.6974\n",
      "Epoch 5/10\n",
      "410/410 - 19s - loss: 1.7675 - accuracy: 0.7402 - val_loss: 2.2153 - val_accuracy: 0.6988\n",
      "Epoch 6/10\n",
      "410/410 - 18s - loss: 1.6948 - accuracy: 0.7490 - val_loss: 2.1648 - val_accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "410/410 - 19s - loss: 1.6237 - accuracy: 0.7552 - val_loss: 2.1344 - val_accuracy: 0.7197\n",
      "Epoch 8/10\n",
      "410/410 - 19s - loss: 1.5659 - accuracy: 0.7607 - val_loss: 2.0926 - val_accuracy: 0.7200\n",
      "Epoch 9/10\n",
      "410/410 - 19s - loss: 1.5102 - accuracy: 0.7661 - val_loss: 2.0767 - val_accuracy: 0.7228\n",
      "Epoch 10/10\n",
      "410/410 - 21s - loss: 1.4619 - accuracy: 0.7705 - val_loss: 2.0567 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f578a92bac0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=10,verbose=2,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ccf933d-e8aa-4f47-b371-d2002d9ca4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "378e6c4c-4281-4258-9088-e5eff0d7f50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jai', 'un', 'un', '', '', '', '', '', '', '', '']], dtype='<U16')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['I have a better idea']\n",
    "tokens = preprocess_inp(test)\n",
    "# print(tokens)\n",
    "pred = model.predict(tokens)\n",
    "vocab_targ[ np.argmax(pred,axis=2)]\n",
    "# print(pred[0][3])\n",
    "# pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
